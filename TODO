TODO LIST FOR PHRED
-------------------

* Ideas

- The subdomaining interface should change so that a function is
  called to decide the number of divisions along each axis, while a
  different function handles breaking up the domain and assigning
  boundary conditions etc. 
  
  New functions:
   - assign_cpus: Assign N cpus along x,y,z axis so that N = n*m*p
   - decomp_domain: For a grid (gx,gy,gz), returns a list of subdomain
     sizes along each axis. 

- Add some library paths to where to look for Python modules. Like
  ~/.phred_fdtd/lib, $install_dir/lib, $PHRED_PYTHON_LIB. 

- Add something to look at the field intensity within the domain every
  so often, and abort the time stepping loop if all components are
  below a certain threshold. 

- FDTD needs some cleaning and refactoring

- The domain decomp algorithm should be able to take a set of 
  (N, M, P) used to indicate the number of cpus along each dimension

- Domain decomp should be able to take into account the additional
  cost of non-contiguous memory when computing the decomposition

- Re-order the loops so that OpenMP divides up along y rather than x,
  since x is the best dimension to divide MPI processes along. z is
  still the inner. 



* Immediate bugs

- UPML buggers up when the domain is decomposed along the z axis. 

----------------------------------------------------------------------

* Various

- Overloaded operator<< for objects which need to print out a
  representation

- Have a generic object that represents configuration, with a
  map<string, Varient> where Varient stores type information and
  data. Boost has a variant.

- Need to fix memory allocation checking... new throws an exception
  when it can't allocate enough memory, older libraries used to have
  new return 0. 



* Sanity
Sanity checks required:

- Ensure excitations apply to some cell in the grid

- Ensure excitations do not overlap boundaries




* Checkpoints



* Save/load problem description in a text file 



* Test cases!!
Unit tests are looking more and more useful, as small changes break
old things all over the place.

- Roast? http://www.cs.uvic.ca/~dhoffman/roast1.2/docs/manual/index.html

- DejaGnu? 

- Boost Test?




* Results

- Near to farfield transformation

- Ensure that the output is always correct for 1, 2, 4 etc MPI
  processors. In particular, getting the order of dimensions backward
  may mess things up. 

- Replace Grid::get_face_start()...



* Excitations

- Total/Scattered

- Periodic boundaries




* Parallel stuff:
- MPI fixups

- OpenMP

- AltiVec

- SSE2

- General vectorization; SSE2 and AlitVec are probably better handled
  by compilers rather than being written by hand. 



